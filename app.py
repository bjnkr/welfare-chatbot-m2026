import streamlit as st
import pandas as pd
import google.generativeai as genai
import requests
import threading
import time

# --------------------------------------------------------------------------
# 1. êµ¬ê¸€ í¼ ë¡œê·¸ ì „ì†¡ í•¨ìˆ˜ (ë¹„ë™ê¸° ì²˜ë¦¬)
# --------------------------------------------------------------------------
def log_to_google_form(question, answer, status):
    def send_request():
        form_url = "https://docs.google.com/forms/d/e/1FAIpQLSfKO_6h_Zge_6__lUhAdEFSZ0tsGXe_6BiMNc3_uJqjsYT-Kw/formResponse"
        data = {
            "entry.878148217": question,
            "entry.1467732690": answer,
            "entry.1569618620": status
        }
        try:
            requests.post(form_url, data=data, timeout=5)
        except:
            pass 

    thread = threading.Thread(target=send_request)
    thread.start()

# --------------------------------------------------------------------------
# 2. í˜ì´ì§€ ì„¤ì •
# --------------------------------------------------------------------------
st.set_page_config(page_title="ë³µì§€ ì±—ë´‡ AI", page_icon="ğŸ¤–")

st.markdown("""
<style>
#MainMenu {visibility: hidden;}
header {visibility: hidden;}
footer {visibility: hidden;}
</style>
""", unsafe_allow_html=True)

# --------------------------------------------------------------------------
# 3. ëª¨ë¸ ì„¤ì • ë° ë°ì´í„° ë¡œë“œ
# --------------------------------------------------------------------------
if "GEMINI_API_KEY" in st.secrets:
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
else:
    st.error("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

@st.cache_data
def load_data():
    url = "https://docs.google.com/spreadsheets/d/e/2PACX-1vT3EmDQ002d2Y8dQkgHE4A_wSErUfgK9xU0QJ8pz0yu_W0F7Q9VN1Es-_OKKJjBobIpZr8tBP3aJQ3-/pub?output=csv"
    try:
        df = pd.read_csv(url)
        return df
    except:
        return pd.DataFrame()

df = load_data()

# --------------------------------------------------------------------------
# 4. ë©”ì¸ UI
# --------------------------------------------------------------------------
with st.sidebar:
    st.markdown("ë³µì§€N ì±—ë´‡ì…ë‹ˆë‹¤")

st.subheader("âœ¨ ê³„ì‚°ê¸° ê´€ë ¨ ì§ˆë¬¸í•´ì£¼ì„¸ìš”")

if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! ë³µì§€N ì…ë‹ˆë‹¤ ê³„ì‚°ê¸° ê´€ë ¨ ë¬¸ì˜í•´ ì£¼ì„¸ìš”."}]

for msg in st.session_state.messages:
    avatar = "ğŸ§š" if msg["role"] == "assistant" else "ğŸ§‘"
    with st.chat_message(msg["role"], avatar=avatar):
        st.write(msg["content"])

# --------------------------------------------------------------------------
# 5. ì§ˆë¬¸ ì²˜ë¦¬ (ëª¨ë¸ Fallback ë¡œì§ ì ìš©)
# --------------------------------------------------------------------------
if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user", avatar="ğŸ§‘"):
        st.write(prompt)

    with st.chat_message("assistant", avatar="ğŸ§š"):
        message_placeholder = st.empty()
        
        if df.empty:
            message_placeholder.error("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            st.stop()

        with st.spinner("ê´€ë ¨ ì •ë³´ë¥¼ ì—´ì‹¬íˆ ì°¾ê³  ìˆì–´ìš”... ğŸ’¬"):
            try:
                # 1. ì „ì²´ ë°ì´í„° ì»¨í…ìŠ¤íŠ¸ (Flash ëª¨ë¸ì€ ëŒ€ìš©ëŸ‰ ì²˜ë¦¬ì— ê°•í•¨)
                full_data = df.to_csv(index=False)
                
                system_prompt = f"""
                ë„ˆëŠ” ìœ ëŠ¥í•œ ì‚¬íšŒë³µì§€ ìƒë‹´ì‚¬ì•¼. ì•„ë˜ [ì°¸ê³  ìë£Œ]ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì¤˜.

                [ì°¸ê³  ìë£Œ]
                {full_data}

                [ê·œì¹™]
                1. ë°˜ë“œì‹œ ì œê³µëœ ìë£Œì— ìˆëŠ” ë‚´ìš©ìœ¼ë¡œë§Œ ë‹µë³€í•´.
                2. ìë£Œì— ì—†ìœ¼ë©´ "ì£„ì†¡í•©ë‹ˆë‹¤. ë°©ê¸ˆí•˜ì‹  ì§ˆë¬¸ì€ ê²Œì‹œíŒì— ë¬¸ì˜ ë°”ëë‹ˆë‹¤."ë¼ê³  ë‹µí•´.
                3. í•µì‹¬ë§Œ ê°„ê²°í•˜ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´.

                [ì§ˆë¬¸]
                {prompt}
                """
                
                # 2. ëª¨ë¸ ì‹œë„ (2.0 Exp -> ì‹¤íŒ¨ ì‹œ 1.5 Flash -> ì‹¤íŒ¨ ì‹œ 1.5 Pro)
                try:
                    # 1ìˆœìœ„: ê°€ì¥ ë¹ ë¥´ê³  ë˜‘ë˜‘í•œ 2.0 Flash Exp
                    model = genai.GenerativeModel("gemini-2.0-flash-exp")
                    response = model.generate_content(system_prompt)
                    answer = response.text
                except Exception as e:
                    # 2ìˆœìœ„: ì•ˆì •ì ì¸ 1.5 Flash
                    # st.toast(f"2.0 ëª¨ë¸ ì‚¬ìš© ë¶ˆê°€, 1.5ë¡œ ì „í™˜í•©ë‹ˆë‹¤. ({e})") # ë””ë²„ê¹…ìš©
                    model = genai.GenerativeModel("gemini-1.5-flash")
                    response = model.generate_content(system_prompt)
                    answer = response.text
                
                message_placeholder.write(answer)

                # ë‹µë³€ ì €ì¥ & ë¡œê·¸
                st.session_state.messages.append({"role": "assistant", "content": answer})
                status = "ì‹¤íŒ¨" if "ì£„ì†¡í•©ë‹ˆë‹¤" in answer else "ì„±ê³µ"
                log_to_google_form(prompt, answer, status)

            except Exception as e:
                message_placeholder.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                log_to_google_form(prompt, f"System Error: {e}", "ì—ëŸ¬")