import streamlit as st
import pandas as pd
import requests
import threading
import sys
import subprocess
import time

# --------------------------------------------------------------------------
# 1. [í•„ìˆ˜] ë¼ì´ë¸ŒëŸ¬ë¦¬ ê°•ì œ ì—…ë°ì´íŠ¸ (ì„œë²„ì•¼ ì •ì‹ ì°¨ë ¤!)
# --------------------------------------------------------------------------
# ì´ ì½”ë“œê°€ ìˆì–´ì•¼ ìµœì‹  ëª¨ë¸(1.5, 2.0) ì´ë¦„ì„ ì¸ì‹í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
try:
    subprocess.check_call([sys.executable, "-m", "pip", "install", "--upgrade", "google-generativeai"])
    import google.generativeai as genai
except Exception as e:
    pass

# --------------------------------------------------------------------------
# 2. ê¸°ë³¸ ì„¤ì •
# --------------------------------------------------------------------------
st.set_page_config(page_title="ë³µì§€ ì±—ë´‡ AI", page_icon="ğŸ’")

st.markdown("""
<style>
#MainMenu {visibility: hidden;}
header {visibility: hidden;}
footer {visibility: hidden;}
</style>
""", unsafe_allow_html=True)

# --------------------------------------------------------------------------
# 3. ë°ì´í„° ë¡œë“œ
# --------------------------------------------------------------------------
@st.cache_data
def load_data():
    url = "https://docs.google.com/spreadsheets/d/e/2PACX-1vT3EmDQ002d2Y8dQkgHE4A_wSErUfgK9xU0QJ8pz0yu_W0F7Q9VN1Es-_OKKJjBobIpZr8tBP3aJQ3-/pub?output=csv"
    try:
        df = pd.read_csv(url)
        return df
    except:
        return pd.DataFrame()

# --------------------------------------------------------------------------
# 4. ë¡œê·¸ ì „ì†¡
# --------------------------------------------------------------------------
def log_to_google_form(question, answer, status):
    def send_request():
        form_url = "https://docs.google.com/forms/d/e/1FAIpQLSfKO_6h_Zge_6__lUhAdEFSZ0tsGXe_6BiMNc3_uJqjsYT-Kw/formResponse"
        data = {
            "entry.878148217": question,
            "entry.1467732690": answer,
            "entry.1569618620": status
        }
        try:
            requests.post(form_url, data=data)
        except:
            pass
    thread = threading.Thread(target=send_request)
    thread.start()

# --------------------------------------------------------------------------
# 5. [í•µì‹¬] ëª¨ë¸ ìë™ ì„ íƒ (2.0 -> 1.5 -> Pro)
# --------------------------------------------------------------------------
def get_generative_model():
    # 1ìˆœìœ„: ì‚¬ìš©ìë‹˜ì´ ì›í•˜ì‹œëŠ” 2.0 (ë¬´ë£Œ ì‹¤í—˜ ë²„ì „)
    try:
        model = genai.GenerativeModel("gemini-2.0-flash-exp")
        model.generate_content("test") # í…ŒìŠ¤íŠ¸ ë°œì‚¬
        return model, "Gemini 2.0 Flash (Exp)"
    except:
        pass

    # 2ìˆœìœ„: 1.5 Flash (ê°€ì„±ë¹„ ìµœê³ )
    try:
        model = genai.GenerativeModel("gemini-1.5-flash")
        model.generate_content("test")
        return model, "Gemini 1.5 Flash"
    except:
        pass

    # 3ìˆœìœ„: ìµœí›„ì˜ ë³´ë£¨ (ì´ê±´ êµ¬ë²„ì „ ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œë„ 100% ë¨)
    try:
        model = genai.GenerativeModel("gemini-pro")
        return model, "Gemini Pro (Legacy)"
    except:
        return None, "Error"

# --------------------------------------------------------------------------
# 6. ë©”ì¸ ë¡œì§
# --------------------------------------------------------------------------
if "GEMINI_API_KEY" in st.secrets:
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
else:
    st.error("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    st.stop()

df = load_data()

# ëª¨ë¸ ë¡œë“œ ì‹œë„
model, model_name = get_generative_model()

with st.sidebar:
    st.image("https://bjn.kr/img_bjn/logo2.png", width=200)
    
    if model:
        st.success(f"âœ… ì—°ê²°ë¨: {model_name}")
    else:
        st.error("âŒ ëª¨ë“  ëª¨ë¸ ì—°ê²° ì‹¤íŒ¨ (APIí‚¤ í™•ì¸ í•„ìš”)")

st.image("https://bjn.kr/img_bjn/logo2.png", width=70)

if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”. ëª¨ì˜ ê³„ì‚°ê¸° ê´€ë ¨ ë¬¸ì˜í•´ ì£¼ì„¸ìš”. ì¼ë°˜ ë³µì§€ê´€ë ¨ ë¬¸ì˜ëŠ” ë³µì•„í˜ ì¹´í˜ ê²Œì‹œíŒì— ë¬¸ì˜ ë°”ëë‹ˆë‹¤.", "avatar": "ğŸ’"}]

for msg in st.session_state.messages:
    with st.chat_message(msg["role"], avatar=msg.get("avatar")):
        st.write(msg["content"])

if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”"):
    st.session_state.messages.append({"role": "user", "content": prompt, "avatar": "ğŸ˜"})
    with st.chat_message("user", avatar="ğŸ˜"):
        st.write(prompt)

    with st.chat_message("assistant", avatar="ğŸ’"):
        message_placeholder = st.empty()
        
        if df.empty:
            message_placeholder.error("ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
            st.stop()
        
        if not model:
            message_placeholder.error("AI ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            st.stop()

        with st.spinner(f"{model_name}ê°€ ë‹µë³€ ì¤‘ì…ë‹ˆë‹¤... ğŸ’¬"):
            try:
                context_data = df.to_csv(index=False)
                
                system_prompt = f"""
                ë„ˆëŠ” 'ë³µì§€N ìƒë‹´ì‚¬'ì•¼. ì•„ë˜ [ì°¸ê³  ìë£Œ]ë¥¼ ë°”íƒ•ìœ¼ë¡œë§Œ ë‹µë³€í•´.
                [ì°¸ê³  ìë£Œ]
                {context_data}
                [ì‚¬ìš©ì ì§ˆë¬¸]
                {prompt}
                """
                
                response = model.generate_content(system_prompt)
                answer = response.text
                
                message_placeholder.write(answer)
                st.session_state.messages.append({"role": "assistant", "content": answer, "avatar": "ğŸ’"})

                is_success = "ì‹¤íŒ¨" if "ì£„ì†¡" in answer else "ì„±ê³µ"
                log_to_google_form(prompt, answer, is_success)

            except Exception as e:
                if "429" in str(e):
                    st.warning("ì´ìš©ëŸ‰ì´ ë§ì•„ ì ì‹œ ì§€ì—°ë˜ì—ˆìŠµë‹ˆë‹¤. 10ì´ˆ ë’¤ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                else:
                    st.error(f"ì˜¤ë¥˜: {e}")