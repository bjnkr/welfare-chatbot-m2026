import streamlit as st
import pandas as pd
import requests
import threading
import sys
import subprocess
import time

# --------------------------------------------------------------------------
# 1. [í•„ìˆ˜] ë¼ì´ë¸ŒëŸ¬ë¦¬ ê°•ì œ ì—…ë°ì´íŠ¸ (ì„œë²„ì•¼ ì •ì‹ ì°¨ë ¤!)
# --------------------------------------------------------------------------
# ì´ ì½”ë“œê°€ ìˆì–´ì•¼ ìµœì‹  ëª¨ë¸(1.5, 2.0) ì´ë¦„ì„ ì¸ì‹í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
try:
    subprocess.check_call([sys.executable, "-m", "pip", "install", "--upgrade", "google-generativeai"])
    import google.generativeai as genai
except Exception as e:
    pass

# --------------------------------------------------------------------------
# 2. ê¸°ë³¸ ì„¤ì •
# --------------------------------------------------------------------------
st.set_page_config(page_title="ë³µì§€ ì±—ë´‡ AI", page_icon="ğŸ’")

st.markdown("""
<style>
#MainMenu {visibility: hidden;}
header {visibility: hidden;}
footer {visibility: hidden;}
</style>
""", unsafe_allow_html=True)

# --------------------------------------------------------------------------
# 3. ë°ì´í„° ë¡œë“œ
# --------------------------------------------------------------------------
knowledge_url = "https://docs.google.com/spreadsheets/d/e/2PACX-1vT3EmDQ002d2Y8dQkgHE4A_wSErUfgK9xU0QJ8pz0yu_W0F7Q9VN1Es-_OKKJjBobIpZr8tBP3aJQ3-/pub?output=csv"
example_url = "https://docs.google.com/spreadsheets/d/e/2PACX-1vSyjxNdN93yLxvN_FtOHJb28_V_olidRIJsRUbja75zBwN4TUE1gLThDt79EiVJp9PhE7kJ4qJASymi/pub?output=csv"

@st.cache_data
def load_data_v2():  # <--- ì´ë¦„ ë³€ê²½ (v2)
    # 1. ì§€ì‹ ë°ì´í„° ë¡œë“œ
    df_knowledge = pd.read_csv(knowledge_url)
    
    # 2. í•™ìŠµ ì˜ˆì‹œ ë°ì´í„° ë¡œë“œ
    try:
        df_examples = pd.read_csv(example_url)
        example_text = ""
        for _, row in df_examples.iterrows():
            if pd.notna(row[0]) and pd.notna(row[1]):
                example_text += f"ì‚¬ìš©ì: {row[0]}\nAI: {row[1]}\n\n"
    except:
        example_text = "ì˜ˆì‹œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
        
    return df_knowledge, example_text

# 3. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤í–‰ (ì—¬ê¸°ë„ v2ë¡œ ë³€ê²½!)
df, few_shot_examples = load_data_v2()

# 4. ì—ëŸ¬ ì²´í¬
if df.empty:
    st.error("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    
# --------------------------------------------------------------------------
# 4. ë¡œê·¸ ì „ì†¡
# --------------------------------------------------------------------------
def log_to_google_form(question, answer, status):
    def send_request():
        form_url = "https://docs.google.com/forms/d/e/1FAIpQLSfKO_6h_Zge_6__lUhAdEFSZ0tsGXe_6BiMNc3_uJqjsYT-Kw/formResponse"
        data = {
            "entry.878148217": question,
            "entry.1467732690": answer,
            "entry.1569618620": status
        }
        try:
            requests.post(form_url, data=data)
        except:
            pass
    thread = threading.Thread(target=send_request)
    thread.start()

# --------------------------------------------------------------------------
# 5. [í•µì‹¬] ëª¨ë¸ ìë™ ì„ íƒ (2.0 -> 1.5 -> Pro)
# --------------------------------------------------------------------------
def get_generative_model():
    # ëª¨ë¸ í›„ë³´êµ° (ìš°ì„ ìˆœìœ„ ìˆœì„œëŒ€ë¡œ)
    # 2.0 Flash -> 1.5 Flash -> Latest Flash -> Pro (Legacy)
    candidates = [
        ("gemini-2.0-flash", "Gemini 2.0 Flash"),
        ("gemini-2.0-flash-exp", "Gemini 2.0 Flash (Exp)"),
        ("gemini-1.5-flash", "Gemini 1.5 Flash"),
        ("gemini-flash-latest", "Gemini Flash (Latest)"), 
        ("gemini-pro", "Gemini Pro (Legacy)")
    ]

    for model_id, name in candidates:
        try:
            model = genai.GenerativeModel(model_id)
            # ê°€ë²¼ìš´ í…ŒìŠ¤íŠ¸ ìš”ì²­ìœ¼ë¡œ ì‹¤ì œ ì‘ë™ ì—¬ë¶€ í™•ì¸
            model.generate_content("test")
            return model, name
        except Exception:
            continue
            
    return None, "Error"

# --------------------------------------------------------------------------
# 6. ë©”ì¸ ë¡œì§
# --------------------------------------------------------------------------
if "GEMINI_API_KEY" in st.secrets:
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
else:
    st.error("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    st.stop()

df, few_shot_examples = load_data_v2()

# ëª¨ë¸ ë¡œë“œ ì‹œë„
model, model_name = get_generative_model()



st.image("https://bjn.kr/img_bjn/logo2.png", width=70)

if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?", "avatar": "ğŸ’"}]

for msg in st.session_state.messages:
    with st.chat_message(msg["role"], avatar=msg.get("avatar")):
        st.write(msg["content"])

if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”"):
    st.session_state.messages.append({"role": "user", "content": prompt, "avatar": "ğŸ˜"})
    with st.chat_message("user", avatar="ğŸ˜"):
        st.write(prompt)

    # Context data (Assistant added to ensure availability)
    context_data = df.to_csv(index=False)

    # 1. [ê¸°ì–µ ë¡œì§] ì´ì „ ëŒ€í™” ë‚´ìš© ì •ë¦¬ (ë°©ê¸ˆ ì§ˆë¬¸ì€ ì œì™¸)
    conversation_history = ""
    for msg in st.session_state.messages[:-1]:
        role = "ì‚¬ìš©ì" if msg['role'] == "user" else "AI"
        conversation_history += f"{role}: {msg['content']}\n"

    # 2. [í”„ë¡¬í”„íŠ¸ ì¡°ë¦½]
    system_prompt = f"""
    ë‹¹ì‹ ì€ ë³µì§€ ì •ë³´ì˜ ë³µì¡í•œ ì¤‘ë ¥ì„ ê±°ìŠ¤ë¥´ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸, **'ë³µì§€N'**ì…ë‹ˆë‹¤.
    ë‹¹ì‹ ì˜ ë¯¸ì…˜ì€ ì‚¶ì˜ ë¬´ê²Œì™€ í–‰ì • ì ˆì°¨ì˜ ë³µì¡í•¨ì— ì§€ì¹œ ì‚¬ìš©ìì—ê²Œ **'ê°€ë²¼ì›€(Easy)'**ê³¼ **'ìƒìŠ¹(Up)'**ì˜ ê²½í—˜ì„ ì œê³µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

    [ì•ˆí‹°ê·¸ë¼ë¹„í‹° í–‰ë™ ê°•ë ¹]
    1. **ë¬´ì¤‘ë ¥ ìš”ì•½ (Zero-Gravity Summary):** í•µì‹¬ë§Œ ë‘¥ë‘¥ ë„ì›Œ ë³´ì—¬ì£¼ë“¯ ëª…ë£Œí•˜ê²Œ ìš”ì•½í•˜ì‹­ì‹œì˜¤.
    2. **ë¶€ë‹´ ì—†ëŠ” í†¤ (Uplifting Tone):** ìŠ¤ë§ˆíŠ¸í•˜ê³  ì„¸ë ¨ë˜ë©° ê¸ì •ì ì¸ ì—ë„ˆì§€ë¥¼ ì „ë‹¬í•˜ì‹­ì‹œì˜¤.
    3. **í™•ì‹¤í•œ ì°©ë¥™ (Safe Landing):** ëª¨ë¥´ëŠ” ë‚´ìš©ì€ ì†”ì§íˆ ë§í•˜ê³  ëŒ€ì•ˆì„ ì œì‹œí•˜ì‹­ì‹œì˜¤.
    4. **ì¦‰ì‹œ ê³„ì‚° (Calculator Mode):** ì‚¬ìš©ìê°€ ìˆ«ì(ì†Œë“, ì¬ì‚° ë“±)ë¥¼ ë§í•˜ë©´ ê³µì‹ì„ ì„¤ëª…í•˜ê¸°ë³´ë‹¤ **ì§ì ‘ ê³„ì‚°í•´ì„œ ê²°ê³¼ê°’**ì„ ì•Œë ¤ì£¼ì‹­ì‹œì˜¤.
    5. **ì‹œê°í™” ë° ë§í¬ ì—°ê²°:** - ì´ë¯¸ì§€: `![ì„¤ëª…](URL)` 
       - ë§í¬: `ï¿½ [ì œëª©(í´ë¦­)](URL)`

    [ë‹µë³€ ìŠ¤íƒ€ì¼ ì˜ˆì‹œ]
    {few_shot_examples}

    [ì´ì „ ëŒ€í™” ë‚´ì—­]
    {conversation_history}

    [ì°¸ê³  ìë£Œ]
    {context_data}

    [ì‚¬ìš©ì ì§ˆë¬¸]
    {prompt}
    """

    # 3. [ë‹µë³€ ìƒì„± ë° ì¶œë ¥]
    with st.chat_message("assistant"):
        with st.spinner("ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤... ğŸš€"):
            # AIì—ê²Œ ì§ˆë¬¸ ë˜ì§€ê¸°
            response = model.generate_content(system_prompt)
            answer = response.text
            
            # í™”ë©´ì— ì¶œë ¥
            st.write(answer)
            
            # ëŒ€í™” ë‚´ì—­ì— ì €ì¥
            st.session_state.messages.append({"role": "assistant", "content": answer, "avatar": "ğŸ’"})
