import streamlit as st
import pandas as pd
import requests
import threading
import sys
import subprocess
import time

# --------------------------------------------------------------------------
# 1. [í•„ìˆ˜] ë¼ì´ë¸ŒëŸ¬ë¦¬ ê°•ì œ ì—…ë°ì´íŠ¸ (ì„œë²„ì•¼ ì •ì‹ ì°¨ë ¤!)
# --------------------------------------------------------------------------
# ì´ ì½”ë“œê°€ ìˆì–´ì•¼ ìµœì‹  ëª¨ë¸(1.5, 2.0) ì´ë¦„ì„ ì¸ì‹í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
try:
    subprocess.check_call([sys.executable, "-m", "pip", "install", "--upgrade", "google-generativeai"])
    import google.generativeai as genai
except Exception as e:
    pass

# --------------------------------------------------------------------------
# 2. ê¸°ë³¸ ì„¤ì •
# --------------------------------------------------------------------------
st.set_page_config(page_title="ë³µì§€ ì±—ë´‡ AI", page_icon="ğŸ’")

st.markdown("""
<style>
#MainMenu {visibility: hidden;}
header {visibility: hidden;}
footer {visibility: hidden;}
</style>
""", unsafe_allow_html=True)

# --------------------------------------------------------------------------
# 3. ë°ì´í„° ë¡œë“œ
# --------------------------------------------------------------------------
knowledge_url = "https://docs.google.com/spreadsheets/d/e/2PACX-1vT3EmDQ002d2Y8dQkgHE4A_wSErUfgK9xU0QJ8pz0yu_W0F7Q9VN1Es-_OKKJjBobIpZr8tBP3aJQ3-/pub?output=csv"
example_url = "https://docs.google.com/spreadsheets/d/e/2PACX-1vSyjxNdN93yLxvN_FtOHJb28_V_olidRIJsRUbja75zBwN4TUE1gLThDt79EiVJp9PhE7kJ4qJASymi/pub?output=csv"

@st.cache_data
def load_data_v2():  # <--- ì´ë¦„ ë³€ê²½ (v2)
    # 1. ì§€ì‹ ë°ì´í„° ë¡œë“œ
    df_knowledge = pd.read_csv(knowledge_url)
    
    # 2. í•™ìŠµ ì˜ˆì‹œ ë°ì´í„° ë¡œë“œ
    try:
        df_examples = pd.read_csv(example_url)
        example_text = ""
        for _, row in df_examples.iterrows():
            if pd.notna(row[0]) and pd.notna(row[1]):
                example_text += f"ì‚¬ìš©ì: {row[0]}\nAI: {row[1]}\n\n"
    except:
        example_text = "ì˜ˆì‹œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
        
    return df_knowledge, example_text

# 3. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤í–‰ (ì—¬ê¸°ë„ v2ë¡œ ë³€ê²½!)
df, few_shot_examples = load_data_v2()

# 4. ì—ëŸ¬ ì²´í¬
if df.empty:
    st.error("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    
# --------------------------------------------------------------------------
# 4. ë¡œê·¸ ì „ì†¡
# --------------------------------------------------------------------------
def log_to_google_form(question, answer, status):
    def send_request():
        form_url = "https://docs.google.com/forms/d/e/1FAIpQLSfKO_6h_Zge_6__lUhAdEFSZ0tsGXe_6BiMNc3_uJqjsYT-Kw/formResponse"
        data = {
            "entry.878148217": question,
            "entry.1467732690": answer,
            "entry.1569618620": status
        }
        try:
            requests.post(form_url, data=data)
        except:
            pass
    thread = threading.Thread(target=send_request)
    thread.start()

# --------------------------------------------------------------------------
# 5. [í•µì‹¬] ëª¨ë¸ ìë™ ì„ íƒ (2.0 -> 1.5 -> Pro)
# --------------------------------------------------------------------------
def get_generative_model():
    # ëª¨ë¸ í›„ë³´êµ° (ìš°ì„ ìˆœìœ„ ìˆœì„œëŒ€ë¡œ)
    # 2.0 Flash -> 1.5 Flash -> Latest Flash -> Pro (Legacy)
    candidates = [
        ("gemini-2.0-flash", "Gemini 2.0 Flash"),
        ("gemini-2.0-flash-exp", "Gemini 2.0 Flash (Exp)"),
        ("gemini-1.5-flash", "Gemini 1.5 Flash"),
        ("gemini-flash-latest", "Gemini Flash (Latest)"), 
        ("gemini-pro", "Gemini Pro (Legacy)")
    ]

    for model_id, name in candidates:
        try:
            model = genai.GenerativeModel(model_id)
            # ê°€ë²¼ìš´ í…ŒìŠ¤íŠ¸ ìš”ì²­ìœ¼ë¡œ ì‹¤ì œ ì‘ë™ ì—¬ë¶€ í™•ì¸
            model.generate_content("test")
            return model, name
        except Exception:
            continue
            
    return None, "Error"

# --------------------------------------------------------------------------
# 6. ë©”ì¸ ë¡œì§
# --------------------------------------------------------------------------
if "GEMINI_API_KEY" in st.secrets:
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
else:
    st.error("API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    st.stop()

df, few_shot_examples = load_data_v2()

# ëª¨ë¸ ë¡œë“œ ì‹œë„
model, model_name = get_generative_model()



st.image("https://bjn.kr/img_bjn/logo2.png", width=70)

if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?", "avatar": "ğŸ’"}]

for msg in st.session_state.messages:
    with st.chat_message(msg["role"], avatar=msg.get("avatar")):
        st.write(msg["content"])

if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”"):
    st.session_state.messages.append({"role": "user", "content": prompt, "avatar": "ğŸ˜"})
    with st.chat_message("user", avatar="ğŸ˜"):
        st.write(prompt)

    with st.chat_message("assistant", avatar="ğŸ’"):
        message_placeholder = st.empty()
        
        if df.empty:
            message_placeholder.error("ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
            st.stop()
        
        if not model:
            message_placeholder.error("AI ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            st.stop()

        with st.spinner(f"{model_name}ê°€ ë‹µë³€ ì¤‘ì…ë‹ˆë‹¤... ğŸ’¬"):
            try:
                context_data = df.to_csv(index=False)
                
                system_prompt = f"""
                ë„ˆëŠ” 'ëŒ€í•œë¯¼êµ­ ìµœê³ ì˜ ë³µì§€ ìƒë‹´ì‚¬'ì•¼. 
                ì‚¬ìš©ìëŠ” ë³µì§€ ì œë„ê°€ ì–´ë µê³  ë³µì¡í•´ì„œ ë„ˆì—ê²Œ ë„ì›€ì„ ìš”ì²­í–ˆì–´.
                ì œê³µëœ [ì°¸ê³  ìë£Œ]ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì¹œêµ¬ë‚˜ ê°€ì¡±ì—ê²Œ ì„¤ëª…í•˜ë“¯ ì‰½ê³  ì¹œì ˆí•˜ê²Œ ë‹µë³€í•´ì¤˜.

                [ì—„ê²©í•œ ë‹µë³€ ê·œì¹™]
                1. **ì•µë¬´ìƒˆ ê¸ˆì§€:** ì°¸ê³  ìë£Œì˜ ë¬¸ì¥ì„ ê·¸ëŒ€ë¡œ ë³µì‚¬í•´ì„œ ë¶™ì—¬ë„£ì§€ ë§ˆ. ë‚´ìš©ì„ ì´í•´í•œ ë’¤ ë„ˆë§Œì˜ ë§íˆ¬ë¡œ ìš”ì•½í•´ì„œ ì„¤ëª…í•´.
                2. **êµ¬ì¡°í™”ëœ ë‹µë³€:** ì¤„ê¸€ë¡œ ê¸¸ê²Œ ëŠ˜ì–´ë†“ì§€ ë§ê³ , ê°€ë…ì„± ìˆê²Œ ë‹µë³€í•´.
                3. **ì¹œì ˆí•œ ë§íˆ¬:** "~ì…ë‹ˆë‹¤/í•©ë‹ˆë‹¤" ëŒ€ì‹  "~ì—ìš”/í•´ìš”" ì²´ë¥¼ ì‚¬ìš©í•˜ê³ , ê³µê°í•˜ëŠ” íƒœë„ë¥¼ ë³´ì—¬ì¤˜.
                4. **ì¶œì²˜ ì¤€ìˆ˜:** ë°˜ë“œì‹œ [ì°¸ê³  ìë£Œ]ì— ìˆëŠ” ë‚´ìš©ë§Œ ì‚¬ì‹¤ë¡œ ê°„ì£¼í•´. ìë£Œì— ì—†ëŠ” ë‚´ìš©ì€ "ì£„ì†¡í•˜ì§€ë§Œ í•´ë‹¹ ë‚´ìš©ì€ ìë£Œì— ì—†ì–´ ì •í™•í•œ ë‹µë³€ì´ ì–´ë µìŠµë‹ˆë‹¤."ë¼ê³  ì†”ì§í•˜ê²Œ ë§í•´.
                5. **ì´ë¯¸ì§€ ì¶œë ¥:** [ì°¸ê³  ìë£Œ]ì— ì´ë¯¸ì§€ ë§í¬(http...)ê°€ ìˆë‹¤ë©´ ë‹µë³€ ëì— `![ì„¤ëª…](ì£¼ì†Œ)` í˜•ì‹ìœ¼ë¡œ ë³´ì—¬ì¤˜.
                
                [ë‹µë³€ ì˜ˆì‹œ]
                ì‚¬ìš©ì: "ìƒê³„ê¸‰ì—¬ ì¡°ê±´ì´ ë­ì•¼?"
                ë‚˜ìœ ë‹µë³€: "ìƒê³„ê¸‰ì—¬ ì„ ì •ê¸°ì¤€ì€ ì†Œë“ì¸ì •ì•¡ì´ ì¤‘ìœ„ì†Œë“ 32% ì´í•˜ì¸ ê°€êµ¬ì…ë‹ˆë‹¤." (X)
                ì¢‹ì€ ë‹µë³€: "ìƒê³„ê¸‰ì—¬ë¥¼ ë°›ìœ¼ì‹œë ¤ë©´ ì†Œë“ì¸ì •ì•¡ì´ ê¸°ì¤€ ì¤‘ìœ„ì†Œë“ì˜ 32%ë³´ë‹¤ ì ì–´ì•¼ í•´ìš”! 
                ì‰½ê²Œ ë§í•´, ê°€êµ¬ì› ìˆ˜ì— ë”°ë¥¸ ê¸°ì¤€ ê¸ˆì•¡ë³´ë‹¤ ì†Œë“ì¸ì •ì•¡ì´ ì ìœ¼ì‹œë©´ ì‹ ì²­ ê°€ëŠ¥í•©ë‹ˆë‹¤.
                
                * **1ì¸ ê°€êµ¬:** 82ë§Œ ì› ì´í•˜
                * **4ì¸ ê°€êµ¬:** 207ë§Œ ì› ì´í•˜
                
                ëª¨ì˜ ê³„ì‚°ê¸°ë¥¼ ì´ìš©í•´ ë³´ì„¸ìš”! ğŸ˜Š" (O)

                [ë‹µë³€ ì˜ˆì‹œ (ìŠ¤íƒ€ì¼ ê°€ì´ë“œ)]
                {few_shot_examples}

                [ì°¸ê³  ìë£Œ]
                {context_data}
                [ì‚¬ìš©ì ì§ˆë¬¸]
                {prompt}
                """
                
                response = model.generate_content(system_prompt)
                answer = response.text
                
                message_placeholder.write(answer)
                st.session_state.messages.append({"role": "assistant", "content": answer, "avatar": "ğŸ’"})

                is_success = "ì‹¤íŒ¨" if "ì£„ì†¡" in answer else "ì„±ê³µ"
                log_to_google_form(prompt, answer, is_success)

            except Exception as e:
                if "429" in str(e):
                    st.warning("ì´ìš©ëŸ‰ì´ ë§ì•„ ì ì‹œ ì§€ì—°ë˜ì—ˆìŠµë‹ˆë‹¤. 10ì´ˆ ë’¤ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                else:
                    st.error(f"ì˜¤ë¥˜: {e}")
